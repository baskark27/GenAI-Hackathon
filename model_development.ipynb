{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler  # Handle class imbalance\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('ecommerce_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset summary\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fill-missing-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill or drop missing values\n",
    "data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-text",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text data\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Assuming 'product' column is the text column you want to clean\n",
    "data['cleaned_text'] = data['product'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert-categorical-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numerical\n",
    "categorical_columns = ['user id', 'product id']\n",
    "data = pd.get_dummies(data, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert-rating-to-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'rating' to binary target\n",
    "data['binary_rating'] = (data['rating'] >= 1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-class-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(data['binary_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['rating', 'product', 'cleaned_text', 'binary_rating'], axis=1)\n",
    "y = data['binary_rating']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handle-class-imbalance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(pd.Series(y_train_bal).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-model-parameters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "vocab_size = 5000\n",
    "embedding_dim = 128\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(128),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile
